{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Import Packages and Settings** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import naive_bayes\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import bigrams\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import os\n",
    "\n",
    "from pylab import figure, axes, pie, title, show\n",
    "\n",
    "import pickle\n",
    "import sys as sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Import Data** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('./train_data/merchantSwipeDump_old.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Import Data Cleaning Module and Clean** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../utility_files')\n",
    "import cleanData\n",
    "\n",
    "cleanData.clean_help()\n",
    "\n",
    "remove_string = '[]' #'^[0-9]*[0-9]$|^www$|^com$|^ave|^street$|^st$|^road$|^and$|^inc$|^at$|^drive$|^of$|^main$|^the$|^[ewns]$|^#|^[0-9]*th$|^[0-9]*rd$|^1st$|^store$|^south$'\n",
    "split_string = \"[- ./*']\"\n",
    "\n",
    "cleanData.clean(data,rejoin_col_strings_bi=True,lowercase=True,split_string=\"[- ./*']\",remove_string = '[]',join_mcc_bi=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Import Dictionary Labels to Expand Train** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data.columns = ['Index'] + list(data.columns[1:])\n",
    "\n",
    "labels = pd.read_csv('./dictionary/dictionary_labels.csv')\n",
    "labels.index = labels.index.set_names(['Index'])\n",
    "labels.reset_index()\n",
    "labels.columns = ['Index'] + list(labels.columns[1:])\n",
    "labels = labels[['Index','mapped_brand_dict_3']]\n",
    "data  = pd.merge(data, labels, how='left', on= 'Index')\n",
    "data = data.fillna('None')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Change mapped_brand to the dictionary guess when None** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mapped_brand_guess'] = np.where(data['mapped_brand']=='None',data['mapped_brand_dict_3'],data['mapped_brand'])\n",
    "# data['mapped_brand_dict_3'] if data['mapped_brand']=='None' else data['mapped_brand']\n",
    "print(len(data[data.mapped_brand_guess!='None']) -len(data[data.mapped_brand_dict_3!='None']))\n",
    "print(len(data[data.mapped_brand_dict_3!='None']))\n",
    "print(len(data[data.mapped_brand!='None']))\n",
    "data.fillna('None_',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Import Train Test Split Module** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../utility_files')\n",
    "import stratifiedSplits\n",
    "\n",
    "stratifiedSplits.stratfiedTrainTestSplit_help()\n",
    "\n",
    "hasLabel,noLabel,X_train, X_test, y_train, y_test = stratifiedSplits.stratfiedTrainTestSplit(df=data, brandCol ='mapped_brand_guess', holdoutPct = .25, ones = 'train')\n",
    "\n",
    "#noLabel = data[data['mapped_brand'].isnull()]\n",
    "noLabel = data[data['mapped_brand_guess']=='None']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\"> **Import NB Module and Run it** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import pickle\n",
    "\n",
    "sys.path.insert(0, '../utility_files')\n",
    "import NaiveBayes\n",
    "\n",
    "\n",
    "NaiveBayes.NB(writeResults = False,makeAllPredictions = True,cleanMerchantCol = 'merchant_string_clean',probThresholdAnalysis=True,\n",
    "              hasLabel=hasLabel,noLabel=noLabel,X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
