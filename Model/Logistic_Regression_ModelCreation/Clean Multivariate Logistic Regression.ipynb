{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "#from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import sklearn.metrics # import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import sklearn.model_selection as ms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('./train_data/merchantSwipeDump_old.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_brand</th>\n",
       "      <th>mcc</th>\n",
       "      <th>merchant_string</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264620</th>\n",
       "      <td>None</td>\n",
       "      <td>5621.0</td>\n",
       "      <td>VICTORIA'S SECRET 0144</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298064</th>\n",
       "      <td>None</td>\n",
       "      <td>4121.0</td>\n",
       "      <td>UBER   *TRIP QZ66O</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42906</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASEYS 4301 STONE A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143923</th>\n",
       "      <td>None</td>\n",
       "      <td>7298.0</td>\n",
       "      <td>MAY FLOWER SPA</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58126</th>\n",
       "      <td>None</td>\n",
       "      <td>5814.0</td>\n",
       "      <td>CHIPOTLE 0666</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247795</th>\n",
       "      <td>None</td>\n",
       "      <td>7832.0</td>\n",
       "      <td>TWIN CREEK CONCESSIONS</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54769</th>\n",
       "      <td>None</td>\n",
       "      <td>7999.0</td>\n",
       "      <td>CHOCTAW C&amp;R THE DISTRI</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>None</td>\n",
       "      <td>5812.0</td>\n",
       "      <td>HAPPY GUY CHINESE CUIS</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280603</th>\n",
       "      <td>None</td>\n",
       "      <td>5541.0</td>\n",
       "      <td>WINGATE CITGO FO</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302548</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UBER *TRIP WD7AB</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>None</td>\n",
       "      <td>5814.0</td>\n",
       "      <td>BURGER KING #12610</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77766</th>\n",
       "      <td>None</td>\n",
       "      <td>5699.0</td>\n",
       "      <td>HOT TOPIC 0322</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154418</th>\n",
       "      <td>None</td>\n",
       "      <td>5734.0</td>\n",
       "      <td>MOTIONARRAY COM</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65711</th>\n",
       "      <td>None</td>\n",
       "      <td>5812.0</td>\n",
       "      <td>GRAND 10 CONCESS</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324344</th>\n",
       "      <td>atm</td>\n",
       "      <td>6011.0</td>\n",
       "      <td>33333 BLUE STAR HIGHWA</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293649</th>\n",
       "      <td>None</td>\n",
       "      <td>4121.0</td>\n",
       "      <td>UBER   *EATS UKBNO</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328950</th>\n",
       "      <td>atm</td>\n",
       "      <td>6011.0</td>\n",
       "      <td>*STRAWBRIDGE MARKETPLA</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7847</th>\n",
       "      <td>None</td>\n",
       "      <td>5814.0</td>\n",
       "      <td>BURGER KING #12633</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34646</th>\n",
       "      <td>None</td>\n",
       "      <td>5812.0</td>\n",
       "      <td>EL JIMADOR VIEGO, LLC</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25821</th>\n",
       "      <td>None</td>\n",
       "      <td>5691.0</td>\n",
       "      <td>AEROPOSTALE #277</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mapped_brand     mcc         merchant_string network\n",
       "264620         None  5621.0  VICTORIA'S SECRET 0144       V\n",
       "298064         None  4121.0      UBER   *TRIP QZ66O       V\n",
       "42906          None     NaN     CASEYS 4301 STONE A     NaN\n",
       "143923         None  7298.0          MAY FLOWER SPA       V\n",
       "58126          None  5814.0           CHIPOTLE 0666       V\n",
       "247795         None  7832.0  TWIN CREEK CONCESSIONS       V\n",
       "54769          None  7999.0  CHOCTAW C&R THE DISTRI       V\n",
       "74995          None  5812.0  HAPPY GUY CHINESE CUIS       V\n",
       "280603         None  5541.0        WINGATE CITGO FO       V\n",
       "302548         None     NaN        UBER *TRIP WD7AB     NaN\n",
       "6219           None  5814.0      BURGER KING #12610       V\n",
       "77766          None  5699.0          HOT TOPIC 0322       V\n",
       "154418         None  5734.0         MOTIONARRAY COM       V\n",
       "65711          None  5812.0        GRAND 10 CONCESS       V\n",
       "324344          atm  6011.0  33333 BLUE STAR HIGHWA       D\n",
       "293649         None  4121.0      UBER   *EATS UKBNO       V\n",
       "328950          atm  6011.0  *STRAWBRIDGE MARKETPLA       D\n",
       "7847           None  5814.0      BURGER KING #12633       V\n",
       "34646          None  5812.0   EL JIMADOR VIEGO, LLC       V\n",
       "25821          None  5691.0        AEROPOSTALE #277       D"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    ## Remove \".0\" from MCC column\n",
    "    df['mcc']=df['mcc'].apply(lambda x: str(x).strip(\".0\"))\n",
    "    ## Change mcc nan to NaN\n",
    "    df['mcc'] = np.where(df['mcc']=='nan', np.nan, df['mcc'])\n",
    "    df['merchant_string'] = df['merchant_string'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Map by MCC as well\n",
    "mcc_dict = {'6011': 'atm', '6010': 'atm', '7523':'parking'}\n",
    "\n",
    "def mcc_dict_funct(df, col_origin, col_output, mcc_dict):\n",
    "    for key, value in mcc_dict.items():\n",
    "            df[col_output] = np.where(df[col_origin]==key, value, df[col_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(df, col):\n",
    "    # Turn merchant string into list and flatten list of sublists\n",
    "    words_merchant_string_2 = [elem for sublist in df[col].tolist() for elem in sublist]\n",
    "\n",
    "    # Get DataFrame of words with their count\n",
    "    wordcnt_df = pd.DataFrame.from_dict(dict(Counter(words_merchant_string_2)), orient='index')\\\n",
    "        .reset_index().rename(columns={\"index\": \"keyword\", 0: \"cnt\"})\\\n",
    "        .sort_values(by='cnt',ascending=False)\n",
    "    most_common_words = list(wordcnt_df['keyword'][0:1000])\n",
    "    most_common_words1 = [\"\\\\\" + x if x[0] == \"*\" else x for x in most_common_words]\n",
    "    return wordcnt_df, most_common_words, most_common_words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummify_data(df, most_common_words1):\n",
    "    for keyword in most_common_words1:\n",
    "        df[keyword] = np.where(df['merchant_string'].str.contains(keyword),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../utility_files')\n",
    "import cleanData\n",
    "\n",
    "preprocess(data)\n",
    "data['mapped_brand_response'] = \"\"\n",
    "mcc_dict_funct(data, 'mcc', 'mapped_brand_response', mcc_dict)\n",
    "\n",
    "remove_string = '^[0-9]*[0-9]$|^www$|^com$|^ave|^street$|^road$|^and$|^inc$|^at$|^drive$|^of$|^main$|^the$|^[ewns]$|^#|^[0-9]*th$|^3rd$|^2nd$|^1st$|^store$|^st$|^rd$|^blvd$|^hwy$|^dr$'\n",
    "split_string = '[-./ ]'\n",
    "\n",
    "cleanData.clean(data, old_col='merchant_string', col='merchant_string1',split_string=split_string,\n",
    "  remove_string = remove_string,lowercase=False, remove_empty_strings_bi=True,\n",
    "  join_mcc_bi=False,rejoin_col_strings_bi=False)\n",
    "\n",
    "wordcnt_df, most_common_words, most_common_words1 = most_common_words(data,'merchant_string1')\n",
    "\n",
    "data_dummified = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 196.6222379207611 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Dummify data (on most common words in merchant string cleaned)\n",
    "start_time = time.time()\n",
    "dummify_data(data_dummified, most_common_words1)  \n",
    "\n",
    "# Dummify additional columns (mcc, network) and drop merchant string column\n",
    "data_dummified=pd.get_dummies(data_dummified, prefix=['mcc', 'network'], columns=['mcc', 'network'])\n",
    "\n",
    "#Delete merchant_string_columns\n",
    "del_cols = ['mapped_brand_response']\n",
    "for x in data_dummified.columns:\n",
    "    if bool(re.search('^merchant_string',x)):\n",
    "        del_cols.append(x)\n",
    "\n",
    "#data_dummified.columns.contain(del_cols), axis = 1)\n",
    "data_dummified =data_dummified.drop(del_cols, axis = 1)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#takes about 7 mins (417 sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test/Holdout\n",
    "def train_test_holdout(df):\n",
    "    # Train and Test from original full dfset\n",
    "    train_full = df[df.mapped_brand.notna()]\n",
    "    test = df[df.mapped_brand.isna()]\n",
    "\n",
    "    # Split into X and y for each set\n",
    "    X_train_full = train_full.drop('mapped_brand', axis=1)\n",
    "    y_train_full = train_full['mapped_brand']\n",
    "    X_test = test.drop('mapped_brand', axis=1)\n",
    "    y_test = test['mapped_brand']\n",
    "\n",
    "    # Train/Holdout split\n",
    "    X_train_wo_holdout, X_holdout, y_train_wo_holdout, y_holdout = train_test_split(\n",
    "         X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Combine X and Y columns for Holdout and Train wo Holdout\n",
    "#     holdout = train_full[train_full.index.isin(X_holdout.index.values)]\n",
    "#     train_wo_holdout = train_full[train_full.index.isin(X_train_wo_holdout.index.values)]\n",
    "    return X_train_full, y_train_full, X_test, y_test, X_train_wo_holdout, X_holdout, y_train_wo_holdout, y_holdout\n",
    "\n",
    "def multinomial_regression(X_train_wo_holdout, y_train_wo_holdout,X_holdout, y_holdout):\n",
    "    multinomial = LogisticRegression(multi_class='multinomial', random_state = 42, solver='lbfgs', C=1e5, class_weight = 'balanced') \n",
    "    multinomial.fit(X_train_wo_holdout, y_train_wo_holdout)\n",
    "    mapped_brand_proba = multinomial.predict_proba(X_holdout)\n",
    "    \n",
    "    probs = pd.DataFrame(mapped_brand_proba)\n",
    "    probs['max_prob'] = probs.max(axis = 1)\n",
    "    probs = probs['max_prob']\n",
    "    \n",
    "    mapped_brand_predicted = multinomial.predict(X_holdout)\n",
    "    \n",
    "    score = multinomial.score(X_holdout, y_holdout)\n",
    "    \n",
    "    mapped_brand_predicted1 = pd.DataFrame(mapped_brand_predicted)\n",
    "    \n",
    "    return multinomial, mapped_brand_proba, probs, mapped_brand_predicted, score, mapped_brand_predicted1\n",
    "\n",
    "def multinomial_output_train(df, mapped_brand_predicted1, probs):\n",
    "#    mapped_brand_predicted1 = pd.DataFrame(mapped_brand_predicted)\n",
    "    X_holdout1 = df.assign(mapped_brand_predicted1=mapped_brand_predicted1.values)[['mapped_brand_predicted1']]\n",
    "    X_holdout1 = X_holdout1.assign(probs = probs.values)\n",
    "    \n",
    "    output = data.join(X_holdout1, how = 'inner')\n",
    "    output['mcc'] = output['mcc'].fillna(-1)\n",
    "    output['network'] = output['network'].fillna(-1)\n",
    "    output['mapped_brand_response'] = np.where(output['mapped_brand_response']=='', output['mapped_brand_predicted1'], output['mapped_brand_response'])\n",
    "    #can add rule about replacing item in column when probability is above a certain threshold\n",
    "    output.drop('mapped_brand_predicted1',axis=1, inplace = True)\n",
    "    \n",
    "    # Add flag on whether mapped brand and predicted mapped brand are same\n",
    "    output['correct_flag'] = np.where(output['mapped_brand'] == output['mapped_brand_response'], 1, 0)\n",
    "\n",
    "    correct_overall = output.agg(['sum','count','mean'])[['correct_flag']]\n",
    "    \n",
    "    correct_by_brand = output.groupby('mapped_brand').agg(['sum','count','mean'])['correct_flag'].reset_index()\\\n",
    "    .sort_values(by='count',ascending=False)\\\n",
    "    .rename(columns={'sum':'nbr_correct', 'count':'nbr_records', 'mean':'pct_correct'})\n",
    "    \n",
    "    return output, correct_overall, correct_by_brand\n",
    "\n",
    "def multinomial_output_test(df, mapped_brand_predicted1, probs):\n",
    "#    mapped_brand_predicted1 = pd.DataFrame(mapped_brand_predicted)\n",
    "    X_holdout1 = df.assign(mapped_brand_predicted1=mapped_brand_predicted1.values)[['mapped_brand_predicted1']]\n",
    "    X_holdout1 = X_holdout1.assign(probs = probs.values)\n",
    "    \n",
    "    output = data.join(X_holdout1, how = 'inner')\n",
    "    output['mcc'] = output['mcc'].fillna(-1)\n",
    "    output['network'] = output['network'].fillna(-1)\n",
    "    output['mapped_brand_response'] = np.where(output['mapped_brand_response']=='', output['mapped_brand_predicted1'], output['mapped_brand_response'])\n",
    "    #can add rule about replacing item in column when probability is above a certain threshold\n",
    "    output.drop('mapped_brand_predicted1',axis=1, inplace = True)\n",
    "    \n",
    "    # Add flag on whether mapped brand and predicted mapped brand are same\n",
    "    output['correct_flag'] = np.where(output['mapped_brand'] == output['mapped_brand_response'], 1, 0)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "mapping_dict = {'vend': 'vendingmachine', #'usa': 'vendingmachine',\n",
    "                'wal-mart': 'walmart', 'walmart': 'walmart', 'wm supercenter': 'walmart',\n",
    "                'uber ': 'uber', # or ubereats\n",
    "                'paypal': 'paypal',\n",
    "                \"mcdonald's\": 'mcdonalds', 'mcdonalds': 'mcdonalds',\n",
    "                'target t-': 'target', 'target.com': 'target',\n",
    "                'cvs/pharm': 'cvs',\n",
    "                'walgreens': 'walgreens',\n",
    "                'starbucks': 'starbucks', \n",
    "                'chick-fil-a': 'chickfila',\n",
    "                'gamestop': 'gamestop', \n",
    "                'google \\*': 'googleplay', # or google,\n",
    "                'kroger': 'kroger',\n",
    "                'chipotle': 'chipotle',\n",
    "                'apl\\* itunes.com/bill': 'appleitunes', # needs a \\ before *\n",
    "                'dunkin': 'dunkindonuts',\n",
    "                'amazon': 'amazon',\n",
    "                'lyft': 'lyft',\n",
    "                '7-eleven': 'seveneleven', '7 eleven': 'seveneleven',\n",
    "                \"victoria's secret\": 'victoriassecret', 'victoriassecret.com':'victoriassecret',\n",
    "                'etsy.com': 'etsy', 'etsy': 'etsy',\n",
    "                'duane reade': 'duanereade',\n",
    "                'taco bell': 'tacobell',\n",
    "                'dollar-general': 'dollargeneral', 'dollar general': 'dollargeneral', 'dollar ge': 'dollargeneral',\n",
    "                \"wendy's\": 'wendys', 'wendys': 'wendys',\n",
    "                'amc ': 'amc',\n",
    "                'safeway store': 'safeway', 'safeway': 'safeway',\n",
    "                'panera bread': 'panerabread',\n",
    "                'subway restaurant': 'subway',\n",
    "                'sonic': 'sonic',\n",
    "                'rite aid store': 'riteaidpharmacy',\n",
    "                'chevron/': 'chevron',\n",
    "                'forever 21': 'forever21',\n",
    "                'dollar tr': 'dollartree',\n",
    "                \"claire's\": 'claires',\n",
    "                'dairy queen': 'dairyqueen',\n",
    "                \"sq \\*tomy's\": 'tomys', # needs a \\ before *\n",
    "                'qt ': 'quiktrip',\n",
    "                'microsoft ': 'microsoft',\n",
    "                'ulta.com': 'ultabeauty', 'ulta #': 'ultabeauty',\n",
    "                'playstation network': 'playstation',\n",
    "                'barnes an': 'barnesandnoble', 'barnes & noble': 'barnesandnoble', 'barnesnob': 'barnesandnoble',\n",
    "                'burger king': 'burgerking',\n",
    "                'riotgam\\*': 'riotgames',\n",
    "                'michaels stores': 'michaels',\n",
    "                'sephora': 'sephora',\n",
    "                'five guys': 'fiveguys', '5guys': 'fiveguys',\n",
    "                'five below': 'fivebelow',\n",
    "                'bath and body works': 'bathandbodyworks', 'bath & body works' : 'bathandbodyworks',\n",
    "                'shake shack': 'shakeshack',\n",
    "                'chopt': 'chopt',\n",
    "                'urban-out': 'urbanoutfitters', 'urban out': 'urbanoutfitters',\n",
    "                \"domino's\": 'dominos',\n",
    "                'regal cinemas': 'regalcinemas', 'edwards':'regalcinemas',\n",
    "                'circle k': 'circlek',\n",
    "                'sweetgreen': 'sweetgreen',\n",
    "                'wholefds': 'wholefoods',\n",
    "                'coca cola': 'cocacola', 'coca-cola': 'cocacola',\n",
    "                'nyctaxi': 'nyctaxi', 'nyc taxi': 'nyctaxi',\n",
    "                'shell': 'shell',\n",
    "                'pacsun': 'pacsun',\n",
    "                'tjmaxx': 'tjmaxx', 't j maxx': 'tjmaxx', 'tj maxx': 'tjmaxx',\n",
    "                'toys r us': 'toysrus',\n",
    "                'lush us': 'lush', 'lush upper west': 'lush',\n",
    "                'best buy': 'bestbuy',\n",
    "                'steamgames.com': 'steam',\n",
    "                'jamba juice': 'jambajuice',\n",
    "                'jimmy johns': 'jimmyjohns'\n",
    "               }\n",
    "def mapping_dict_funct(df, col_origin, col_output, mapping_dict):\n",
    "    for key, value in mapping_dict.items():\n",
    "        df[col_output] = np.where(df[col_origin].str.contains(key), value, df[col_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummified3 = data_dummified[(data_dummified['mcc_6011'] != 1)]\n",
    "data_dummified4 = data_dummified3[(data_dummified3['mcc_7523'] != 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.02 s, sys: 3.31 s, total: 6.33 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test/Train/Holdout split, saving off each df returned\n",
    "X_train_full, y_train_full, X_test, y_test, X_train_wo_holdout, X_holdout, y_train_wo_holdout, y_holdout = \\\n",
    "train_test_holdout(data_dummified4) \n",
    "\n",
    "# can add input parameter for 80/20 split\n",
    "#takes about 14 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 3.51 s, total: 1min 39s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multinomial_train, mapped_brand_proba_train, probs_train, mapped_brand_predicted_train, score_train, mapped_brand_predicted1_train = multinomial_regression(X_train_wo_holdout, y_train_wo_holdout, X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525831564048125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, correct_overall, correct_by_brand = multinomial_output_train(X_holdout, mapped_brand_predicted1_train, probs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_brand</th>\n",
       "      <th>mcc</th>\n",
       "      <th>merchant_string</th>\n",
       "      <th>network</th>\n",
       "      <th>mapped_brand_response</th>\n",
       "      <th>merchant_string1</th>\n",
       "      <th>probs</th>\n",
       "      <th>correct_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314731</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>5814</td>\n",
       "      <td>starbucks store 17000</td>\n",
       "      <td>V</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>[starbucks]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314734</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>5814</td>\n",
       "      <td>starbucks store 00885</td>\n",
       "      <td>V</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>[starbucks]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314737</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>5814</td>\n",
       "      <td>starbucks store 47931</td>\n",
       "      <td>V</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>[starbucks]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314748</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>5814</td>\n",
       "      <td>starbucks store 29856</td>\n",
       "      <td>V</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>[starbucks]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314750</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>5814</td>\n",
       "      <td>starbucks store 21929</td>\n",
       "      <td>V</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>[starbucks]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mapped_brand   mcc        merchant_string network  \\\n",
       "314731    starbucks  5814  starbucks store 17000       V   \n",
       "314734    starbucks  5814  starbucks store 00885       V   \n",
       "314737    starbucks  5814  starbucks store 47931       V   \n",
       "314748    starbucks  5814  starbucks store 29856       V   \n",
       "314750    starbucks  5814  starbucks store 21929       V   \n",
       "\n",
       "       mapped_brand_response merchant_string1  probs  correct_flag  \n",
       "314731             starbucks      [starbucks]    1.0             1  \n",
       "314734             starbucks      [starbucks]    1.0             1  \n",
       "314737             starbucks      [starbucks]    1.0             1  \n",
       "314748             starbucks      [starbucks]    1.0             1  \n",
       "314750             starbucks      [starbucks]    1.0             1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9418026969481902"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[(output['correct_flag'] == 1) & \\\n",
    "           (output['mcc'] !='6011') & \\\n",
    "           (output['mcc'] !='7523')])/len(output[(output['mcc'] !='6011') & (output['mcc'] !='7523')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_full1 = y_train_full[(y_train_full['mcc'] !='6011') & (y_train_full['mcc'] !='7523')]\n",
    "#y_train_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 1min 2s, total: 4min 37s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#THIS TAKES ABOUT 8 MINS TO RUN\n",
    "y_test.fillna(\"Unknown\", inplace = True)\n",
    "#testing model on test using full train set\n",
    "multinomial, mapped_brand_proba, probs, mapped_brand_predicted, score, mapped_brand_predicted1 = multinomial_regression(X_train_full, y_train_full, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 s, sys: 4.41 s, total: 6.7 s\n",
      "Wall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output = multinomial_output_test(X_test, mapped_brand_predicted1, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merchant_col(output, 'merchant_string', 'merchant_string_dict') # so not cleaned\n",
    "lowercase_col(output, 'merchant_string_dict') # dictionary below needs lowercase to work\n",
    "output['mapped_brand_dict_3'] = ''\n",
    "\n",
    "# Run dictionary functions on data\n",
    "mapping_dict_funct(output, 'merchant_string_dict', 'mapped_brand_dict_3', mapping_dict)\n",
    "mcc_dict_funct(output, 'mcc', 'mapped_brand_dict_3', mcc_dict)\n",
    "# Create new column flags for predicted, correct, train/test, row count\n",
    "# Can be used to summarize, if desired\n",
    "output['predicted_flag'] = np.where(output['mapped_brand_dict_3'] != '',1,0)\n",
    "output['equals_prediced_flag_1'] = np.where(output['mapped_brand_response'] == output['mapped_brand_dict_3'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_model_output = output[(output['mcc'] !='6011') & (output['mcc'] !='7523') & (output['predicted_flag'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_accuracy = test_model_output.mean()[['equals_prediced_flag_1']]\n",
    "test_accuracy = test_model_output.mean()[['equals_predicted_flag']]\n",
    "###TAKES 46 MINUTES TO RUN\n",
    "####ACCURACY: 0.99127!!!!!!\n",
    "#####Potentially faster ways to get accuracy\n",
    "##1\n",
    "#test_model_output['equals_prediced_flag_1'].mean()\n",
    "##2\n",
    "#incorrect_test_model_output = output[(output['mcc'] !='6011') & (output['mcc'] !='7523') & (output['predicted_flag'] != 1)]\n",
    "#len(incorrect_test_model_output)/len(test_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "equals_prediced_flag_1    0.99127\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_output[test_model_output['equals_predicted_flag_1'] == 0]\n",
    "# ideas: remove ATM/parking, a number of best buy/burger kind wrong, maybe remove edwards or vend from dictionary, maybe stopword restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output[(output['mcc'] !='6011') & (output['mcc'] !='7523') & (output['predicted_flag'] != 1)].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[(output['mcc'] !='6011') & (output['mcc'] !='7523') & (output['predicted_flag'] == 1)].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(test_model_output['mapped_brand_dict_3'], test_model_output['mapped_brand_response'])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=test_model_output['mapped_brand_response'].values, yticklabels=test_model_output['mapped_brand_dict_3'].values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uber             24166\n",
       "paypal           11552\n",
       "mcdonalds         9155\n",
       "starbucks         4566\n",
       "dollargeneral     3947\n",
       "walmart           3788\n",
       "walgreens         3650\n",
       "tacobell          2991\n",
       "gamestop          2777\n",
       "dunkindonuts      2743\n",
       "cvs               2637\n",
       "target            2629\n",
       "dollartree        2410\n",
       "wendys            2360\n",
       "burgerking        2181\n",
       "kroger            2023\n",
       "sonic             1813\n",
       "googleplay        1770\n",
       "chickfila         1700\n",
       "dominos           1508\n",
       "Name: mapped_brand_dict_3, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_output['mapped_brand_dict_3'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_model_output['mapped_brand_response'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "def save_as_pickled_object(obj, filepath):\n",
    "    max_bytes = 2**31 - 1\n",
    "    bytes_out = pickle.dumps(obj)\n",
    "    n_bytes = sys.getsizeof(bytes_out)\n",
    "    with open(filepath, 'wb') as f_out:\n",
    "        for idx in range(0, n_bytes, max_bytes):\n",
    "            f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "\n",
    "\n",
    "save_as_pickled_object(multinomial,'final_ML_model.sav')\n",
    "\n",
    "import os\n",
    "def try_to_load_as_pickled_object_or_None(filepath):\n",
    "            \"\"\"\n",
    "            This is a defensive way to write pickle.load, allowing for very large files on all platforms\n",
    "            \"\"\"\n",
    "            max_bytes = 2**31 - 1\n",
    "\n",
    "            input_size = os.path.getsize(filepath)\n",
    "            bytes_in = bytearray(0)\n",
    "            with open(filepath, 'rb') as f_in:\n",
    "                for _ in range(0, input_size, max_bytes):\n",
    "                    bytes_in += f_in.read(max_bytes)\n",
    "            obj = pickle.loads(bytes_in)\n",
    "\n",
    "            return obj\n",
    "\n",
    "multinomial2 = try_to_load_as_pickled_object_or_None('final_ML_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.7 s, sys: 31.5 s, total: 1min 22s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#len(multinomial2.predict(X_test))\n",
    "#314152\n",
    "#len(multinomial.predict(X_test))\n",
    "#314152\n",
    "sum(multinomial2.predict(X_test) != multinomial.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_holdout1 = X_holdout.copy()\n",
    "#X_holdout1['multinom_pickle'] = multinomial2.predict(X_holdout)\n",
    "#X_holdout1['multinom'] = multinomial_train.predict(X_holdout)\n",
    "#X_holdout1[X_holdout1['multinom_pickle'] != X_holdout1['multinom']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
